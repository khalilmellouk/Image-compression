{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Required$ $Libraries$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Pour tracer des graphiques\n",
    "import numpy as np  # Pour manipuler des tableaux multidimensionnels\n",
    "from sklearn.cluster import KMeans  # Pour effectuer le clustering KMeans\n",
    "from PIL import Image  # Pour manipuler des images\n",
    "import os  # Pour accéder aux fonctionnalités du système d'exploitation\n",
    "import cv2  # Pour la manipulation d'images (OpenCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Data/Information$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des fichiers d'entrée et de sortie\n",
    "input_image_path = 'eren.jpg'  # Chemin de l'image d'entrée\n",
    "input_irm_path = 'file.irm'  # Chemin du fichier IRM d'entrée\n",
    "output_image_path = 'reconstituted.jpg'  # Chemin de l'image de sortie reconstruite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Features$ of $the$ $image$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_details(path):\n",
    "    # Ouvrir l'image à partir du chemin donné\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    # Obtenir la taille de l'image (largeur, hauteur)\n",
    "    size = img.size\n",
    "    \n",
    "    # Obtenir le format de l'image (JPEG, PNG, etc.)\n",
    "    format = img.format\n",
    "    \n",
    "    # Obtenir le mode de l'image (RGB, L, etc.)\n",
    "    mode = img.mode\n",
    "    \n",
    "    # Obtenir la résolution de l'image si disponible (en DPI)\n",
    "    resolution = img.info.get('dpi')\n",
    "    \n",
    "    # Calculer la définition de l'image (nombre total de pixels)\n",
    "    definition = size[0] * size[1]\n",
    "    \n",
    "    # Stocker également la taille originale de l'image\n",
    "    definition2 = size\n",
    "    \n",
    "    # Si la résolution est disponible, ajuster la taille en fonction de la résolution\n",
    "    if resolution is not None:\n",
    "        size = (size[0] / resolution[0], size[1] / resolution[1])\n",
    "    else:\n",
    "        size = (0, 0)  # ou toute résolution par défaut que vous souhaitez utiliser\n",
    "    \n",
    "    # Obtenir la taille du fichier en kilobytes\n",
    "    poids = os.path.getsize(path) / 1000.0\n",
    "    \n",
    "    # Calculer le nombre total de bits de l'image\n",
    "    if mode == 'RGB':\n",
    "        trsc = definition * 3 * img.bits\n",
    "    else:\n",
    "        trsc = definition * 1 * img.bits\n",
    "    \n",
    "    # Convertir le nombre total de bits en kilobits\n",
    "    trsc /= (1024 * 8)\n",
    "    \n",
    "    # Calculer le taux de compression en pourcentage\n",
    "    taux_compression = 100 * (1 - (poids / trsc))\n",
    "    \n",
    "    # Retourner toutes les informations collectées sous forme de tuple\n",
    "    return size, format, mode, resolution, definition, definition2, poids, trsc, taux_compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Display$ $any$ $two$ $images$ $side$ $by$ $side$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(original_path, modified_path):\n",
    "    # Ouvrir l'image originale depuis le chemin spécifié\n",
    "    img1 = Image.open(original_path)\n",
    "    \n",
    "    # Ouvrir l'image modifiée (reconstruite) depuis le chemin spécifié\n",
    "    img2 = Image.open(modified_path)\n",
    "    \n",
    "    # Créer une figure et des sous-graphiques pour afficher les deux images côte à côte\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 15))  # Créer une figure avec une rangée et deux colonnes\n",
    "    fig.subplots_adjust(wspace=0.01)  # Ajuster l'espace entre les sous-graphiques\n",
    "    \n",
    "    # Afficher l'image originale dans le premier sous-graphique\n",
    "    axs[0].imshow(img1)\n",
    "    axs[0].set_title('Image initiale')  # Définir le titre du premier sous-graphique\n",
    "    axs[0].axis('off')  # Désactiver les axes du premier sous-graphique\n",
    "    \n",
    "    # Afficher l'image reconstruite dans le deuxième sous-graphique\n",
    "    axs[1].imshow(img2)\n",
    "    axs[1].set_title('Image reconstruite')  # Définir le titre du deuxième sous-graphique\n",
    "    axs[1].axis('off')  # Désactiver les axes du deuxième sous-graphique\n",
    "    \n",
    "    # Ajuster la disposition de la figure pour éviter les chevauchements\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Afficher la figure avec les deux images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Mean$ $Square$ $Error$ $(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(original_image_path, processed_image_path):\n",
    "    # Charger les images\n",
    "    image_originale = Image.open(original_image_path)\n",
    "    image_traitee = Image.open(processed_image_path)\n",
    "\n",
    "    # Convertir les images en tableaux NumPy\n",
    "    origine = np.array(image_originale)\n",
    "    traitee = np.array(image_traitee)\n",
    "\n",
    "    # Assurer que les images ont les mêmes dimensions\n",
    "    if origine.shape != traitee.shape:\n",
    "        raise ValueError(\"Les dimensions des images sont différentes.\")\n",
    "\n",
    "    # Calculer la somme des différences au carré\n",
    "    somme_differences_carrees = np.sum((origine.astype(np.float32) - traitee.astype(np.float32)) ** 2)\n",
    "\n",
    "    # Calculer (1 / (L * C)) * somme\n",
    "    resultat = (1 / (origine.shape[0] * origine.shape[1])) * somme_differences_carrees\n",
    "\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Compression$ $rate$ $with$ $respect$ $to$ $the$ $data$ $of$ $files$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_ratio(chemin_image, chemin_donnees_compressées):\n",
    "    # Ouvrir l'image depuis le chemin spécifié\n",
    "    img = Image.open(chemin_image)\n",
    "    \n",
    "    # Déterminer la taille des pixels en fonction du mode de couleur de l'image\n",
    "    if img.mode == 'RGB':\n",
    "        pixel_size = 3  # Nombre de canaux de couleur (Rouge, Vert, Bleu)\n",
    "    else:\n",
    "        pixel_size = 1  # Pour d'autres modes de couleur\n",
    "    \n",
    "    # Déterminer la taille en bits par pixel\n",
    "    if img.bits == 8:\n",
    "        pixel_bits = 8  # Pour les images 8 bits par pixel\n",
    "    else:\n",
    "        pixel_bits = 16  # Pour les images 16 bits par pixel (peut être ajusté selon les besoins)\n",
    "    \n",
    "    # Calculer la taille des données de l'image en bits\n",
    "    img_data_size = img.size[0] * img.size[1] * pixel_size * pixel_bits\n",
    "    \n",
    "    # Calculer la taille des données compressées en bits\n",
    "    taille_données_compressées = os.path.getsize(chemin_donnees_compressées) * 8\n",
    "    \n",
    "    # Calculer le taux de compression\n",
    "    taux_de_compression = 1 - (taille_données_compressées / img_data_size)\n",
    "    \n",
    "    return taux_de_compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1). $Transition$ $from$ $the$ $color$ $space$ $RGB$ $to$ $the$ $color$ $space$ $YCrCb$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sense$ $normal$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_ycbcr(rgb_image):\n",
    "    rgb_image = np.array(rgb_image)\n",
    "    ycrcb_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)\n",
    "    return ycrcb_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $inverse$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ycbcr_to_rgb(ycrcb_image):\n",
    "    rgb_image = cv2.cvtColor(np.array(ycrcb_image), cv2.COLOR_YCrCb2RGB)\n",
    "    # Convert numpy array to PIL Image\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    # Save the PIL Image\n",
    "    return rgb_image_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2). $Creation$ $of$ $the$ $color$ $palette$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sense$ $alley$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k-means$ $clustering$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering_palette(image, num_colors):\n",
    "    # Convert the image into a 2D array of pixels\n",
    "    pixels = np.reshape(image, (-1, 3))  # (number of pixels, 3 color channels)\n",
    "\n",
    "    # Apply the k-means clustering algorithm\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Get the cluster centers (dominant colors)\n",
    "    color_palette = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    # Associate each pixel with the color index in the palette\n",
    "    labels = kmeans.predict(pixels)\n",
    "\n",
    "    # Reshape the color indices in the palette according to the shape of the original image\n",
    "    palette_indices = np.reshape(labels, np.array(image).shape[:2])\n",
    "\n",
    "    return color_palette, palette_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sense$ $return$\n",
    "\n",
    "### $k-means$ $clustering$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_kmeans_clustering_palette(color_palette, palette_indices):\n",
    "    # Récupérer les dimensions de l'image à partir des indices de la palette\n",
    "    height, width = palette_indices.shape\n",
    "\n",
    "    # Initialiser une image vide avec les dimensions récupérées\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplir l'image reconstruite avec les couleurs de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = palette_indices[i, j]  # Obtenir l'indice de couleur pour le pixel actuel\n",
    "            reconstructed_image[i, j] = color_palette[color_index]  # Assigner la couleur correspondante de la palette\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3). $Mapping$ $of$ $pixels$\n",
    "\n",
    "## (a). $Direction$ $\"alley\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_palette(image, color_palette):\n",
    "    # Assurez-vous que l'image est sous forme de tableau numpy\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # Redimensionner les pixels en une matrice (nombre de pixels, 3 canaux de couleur)\n",
    "    pixels = np.reshape(image, (-1, 3))  \n",
    "\n",
    "    # Calculer la distance de chaque pixel à chaque couleur de la palette\n",
    "    distances = np.linalg.norm(pixels[:, np.newaxis] - color_palette, axis=2)\n",
    "\n",
    "    # Obtenir l'indice de la couleur la plus proche pour chaque pixel\n",
    "    indices = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Reformater les indices des couleurs selon la forme de l'image originale\n",
    "    mapped_indices = np.reshape(indices, image.shape[:2])\n",
    "\n",
    "    return np.array(mapped_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Meaning$ $\"return\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_map_to_palette(mapped_indices, color_palette):\n",
    "    # Obtenir les dimensions de l'image reconstruite\n",
    "    height, width = mapped_indices.shape\n",
    "\n",
    "    # Créer une image vide\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Pour chaque pixel, assigner la couleur correspondante de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = mapped_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "\n",
    "    # Convertir le tableau numpy en objet Image PIL\n",
    "    return Image.fromarray(reconstructed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4). $Subdivision$ $in$ $blocks$\n",
    "\n",
    "## (a). $Direction$ $\"alley\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdivision(matrice, taille_blocs):\n",
    "    # Dimensions de la matrice initiale\n",
    "    lignes, colonnes = matrice.shape\n",
    "    \n",
    "    # Dimensions des blocs\n",
    "    blocs_lignes, blocs_colonnes = (taille_blocs, taille_blocs)\n",
    "    \n",
    "    # Calcul des dimensions des blocs avec zéros ajoutés\n",
    "    new_blocs_lignes = (lignes + blocs_lignes - 1) // blocs_lignes\n",
    "    new_blocs_colonnes = (colonnes + blocs_colonnes - 1) // blocs_colonnes\n",
    "    \n",
    "    # Initialisation de la matrice des sous-matrices\n",
    "    sous_matrices = np.zeros((new_blocs_lignes, new_blocs_colonnes, blocs_lignes, blocs_colonnes))\n",
    "    \n",
    "    # Remplissage de la matrice des sous-matrices\n",
    "    for i in range(new_blocs_lignes):\n",
    "        for j in range(new_blocs_colonnes):\n",
    "            sous_matrices[i, j, :min(blocs_lignes, lignes - i*blocs_lignes), :min(blocs_colonnes, colonnes - j*blocs_colonnes)] = \\\n",
    "                matrice[i*blocs_lignes:(i+1)*blocs_lignes, j*blocs_colonnes:(j+1)*blocs_colonnes]\n",
    "    \n",
    "    # Convertir la matrice de sous-matrices en une liste de matrices 2D\n",
    "    liste_matrices = []\n",
    "    for i in range(new_blocs_lignes):\n",
    "        for j in range(new_blocs_colonnes):\n",
    "            liste_matrices.append(sous_matrices[i, j])\n",
    "    \n",
    "    # Retourner la liste de matrices 2D et les dimensions originales de la matrice\n",
    "    return liste_matrices, (lignes, colonnes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Meaning$ $\"return\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstitution(liste_matrices, dimensions):\n",
    "    # Récupération des dimensions de la matrice initiale\n",
    "    lignes, colonnes = dimensions\n",
    "    \n",
    "    # Initialisation de la matrice résultante avec des zéros\n",
    "    matrice_resultante = np.zeros((lignes, colonnes))\n",
    "    \n",
    "    # Dimensions des blocs\n",
    "    taille_blocs = liste_matrices[0].shape\n",
    "    \n",
    "    # Nombre de blocs\n",
    "    nb_blocs_lignes = (lignes + taille_blocs[0] - 1) // taille_blocs[0]\n",
    "    nb_blocs_colonnes = (colonnes + taille_blocs[1] - 1) // taille_blocs[1]\n",
    "    \n",
    "    # Recombinaison des sous-matrices dans la matrice résultante\n",
    "    for i in range(nb_blocs_lignes):\n",
    "        for j in range(nb_blocs_colonnes):\n",
    "            matrice_resultante[i*taille_blocs[0]:(i+1)*taille_blocs[0], j*taille_blocs[1]:(j+1)*taille_blocs[1]] = \\\n",
    "                liste_matrices[i*nb_blocs_colonnes + j][:min(taille_blocs[0], lignes - i*taille_blocs[0]), :min(taille_blocs[1], colonnes - j*taille_blocs[1])]\n",
    "    \n",
    "    # Retourner la matrice résultante en tant que tableau numpy avec des entiers 64 bits\n",
    "    return np.array(matrice_resultante, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5). $Undersampling$\n",
    "\n",
    "## (a). $Direction$ $\"alley\"$\n",
    "\n",
    "### $4:4:4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling_4_4_4(image):\n",
    "    # La fonction ne fait rien car il n'y a pas de sous-échantillonnage pour le 4:4:4\n",
    "    return image.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sense$ $\"return\"$\n",
    "\n",
    "### $4:4:4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_subsampling_4_4_4(imSub):\n",
    "    # L'inverse du sous-échantillonnage 4:4:4 est simplement une copie de l'image d'entrée\n",
    "    return imSub.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6). $Vectorization$\n",
    "\n",
    "## (a). $Direction$ $\"alley\"$\n",
    "\n",
    "### $In$ $line$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_scan(matrice):\n",
    "    # Récupérer les dimensions de la matrice\n",
    "    shape = matrice.shape\n",
    "    \n",
    "    # Aplatir la matrice en un vecteur unidimensionnel\n",
    "    vecteur = matrice.flatten()\n",
    "    \n",
    "    # Retourner le vecteur résultant et les dimensions originales de la matrice\n",
    "    return np.array(vecteur), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sense$ $\"return\"$\n",
    "\n",
    "### $In$ $line$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_linear_scan(vecteur, shape):\n",
    "    # Remodeler le vecteur en une matrice avec les dimensions originales\n",
    "    matrice = np.array(vecteur).reshape((shape[0], shape[1]))\n",
    "    \n",
    "    # Retourner la matrice résultante\n",
    "    return matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7). $Coding$ $by$ $RLE$\n",
    "\n",
    "## (a). $Direction$ $\"alley\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(data):\n",
    "    encoded_data = \"\"  # Initialisation de la chaîne encodée\n",
    "    current_char = data[0]  # Première caractère dans les données\n",
    "    count = 1  # Initialisation du compteur de répétitions\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == current_char:\n",
    "            count += 1  # Incrémenter le compteur si le caractère actuel est identique au précédent\n",
    "        else:\n",
    "            if count > 1:  # Si le compteur est supérieur à 1, ajouter le caractère et le compteur à la chaîne encodée\n",
    "                encoded_data += str(current_char) + \"_\" + str(count) + \"*\"  # Ajouter le caractère et le compteur\n",
    "            else:\n",
    "                encoded_data += str(current_char) + \"*\"  # Ajouter uniquement le caractère\n",
    "            current_char = data[i]  # Mettre à jour le caractère actuel\n",
    "            count = 1  # Réinitialiser le compteur\n",
    "\n",
    "    if count > 1:  # Gérer le dernier caractère après la boucle\n",
    "        encoded_data += str(current_char) + \"_\" + str(count)  # Ajouter le caractère et le compteur\n",
    "    else:\n",
    "        encoded_data += str(current_char)  # Ajouter uniquement le caractère\n",
    "\n",
    "    return encoded_data  # Retourner la chaîne encodée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Meaning$ $\"return\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(encoded_data):\n",
    "    decoded_data = []  # Initialisation de la liste des données décodées\n",
    "    encoded_data_split = encoded_data.split('*')  # Diviser la chaîne encodée en parties séparées\n",
    "\n",
    "    for item in encoded_data_split:\n",
    "        if \"_\" in item:  # Si le caractère \"_\" est présent, cela signifie qu'il y a une répétition\n",
    "            char, count = item.split(\"_\")  # Séparer le caractère et le nombre de répétitions\n",
    "            char = float(char)  # Convertir le caractère en float\n",
    "            if char.is_integer():  # Vérifier si le caractère est un entier\n",
    "                char = int(char)  # Convertir le caractère en entier\n",
    "            decoded_data.extend([char] * int(count))  # Ajouter le caractère répété au nombre de fois spécifié\n",
    "        else:\n",
    "            char = float(item)  # Convertir le caractère en float\n",
    "            if char.is_integer():  # Vérifier si le caractère est un entier\n",
    "                char = int(char)  # Convertir le caractère en entier\n",
    "            decoded_data.append(char)  # Ajouter le caractère simple à la liste des données décodées\n",
    "\n",
    "    return decoded_data  # Retourner les données décodées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (8). $Coding$ $of$ $Huffman$\n",
    "\n",
    "## (-). $Intermediate$ $functions$ $(specific$ $to$ $Huffman)$\n",
    "\n",
    "### $Extraction$ $of$ $characters$ $and$ $their$ $frequency$ $of $appearance$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_chr(chaine):\n",
    "    # Créer un dictionnaire contenant le nombre d'occurrences de chaque caractère dans la chaîne\n",
    "    occurences = {c: chaine.count(c) for c in set(chaine)}\n",
    "    \n",
    "    # Trier le dictionnaire par valeur (nombre d'occurrences) dans l'ordre décroissant\n",
    "    occurences_triees = sorted(occurences.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Retourner les résultats triés\n",
    "    return occurences_triees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Dictionary$ $of$ $Huffman$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_dictionnary_code(node, binString=''):\n",
    "    # Si le nœud est une feuille (représentée par une chaîne), retourner un dictionnaire avec le code binaire\n",
    "    if isinstance(node, str):\n",
    "        return {node: binString}\n",
    "    \n",
    "    # Si le nœud est un nœud interne, récursivement créer le dictionnaire de codes pour ses enfants\n",
    "    (l, r) = node\n",
    "    d = {}\n",
    "    # Mettre à jour le dictionnaire avec les codes binaires des enfants\n",
    "    d.update(huffman_dictionnary_code(l, binString + '0'))\n",
    "    d.update(huffman_dictionnary_code(r, binString + '1'))\n",
    "    \n",
    "    # Retourner le dictionnaire de codes\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Huffman$ $Tree$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_tree(chaine):\n",
    "    # Créer une liste de tuples contenant chaque caractère et son nombre d'occurrences\n",
    "    nodes = ext_chr(chaine)\n",
    "    \n",
    "    # Tant qu'il reste plus d'un nœud dans la liste\n",
    "    while len(nodes) > 1:\n",
    "        # Extraire les deux nœuds ayant le moins d'occurrences\n",
    "        (key1, c1) = nodes.pop()\n",
    "        (key2, c2) = nodes.pop()\n",
    "        \n",
    "        # Créer un nouveau nœud en combinant les deux nœuds précédents\n",
    "        node = (key1, key2)\n",
    "        \n",
    "        # Ajouter le nouveau nœud à la liste avec la somme de leurs occurrences\n",
    "        nodes.append((node, c1 + c2))\n",
    "        \n",
    "        # Trier la liste en fonction du nombre d'occurrences, en ordre décroissant\n",
    "        nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    # Le dernier nœud restant est la racine de l'arbre de Huffman\n",
    "    return nodes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Coding$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_encoding(string):\n",
    "    # Créer l'arbre de Huffman à partir de la chaîne donnée\n",
    "    nodes = huffman_tree(string)\n",
    "    \n",
    "    # Générer le dictionnaire de codes Huffman à partir de l'arbre\n",
    "    huffmanCode = huffman_dictionnary_code(nodes)\n",
    "    \n",
    "    # Initialiser une chaîne vide pour stocker la chaîne compressée\n",
    "    compressed_string = ''\n",
    "    \n",
    "    # Parcourir chaque caractère de la chaîne d'entrée\n",
    "    for char in string:\n",
    "        # Ajouter le code Huffman correspondant à chaque caractère à la chaîne compressée\n",
    "        compressed_string += huffmanCode[char]\n",
    "    \n",
    "    # Retourner la chaîne compressée et l'arbre de Huffman\n",
    "    return compressed_string, nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Decoding$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_decoding(compressed_string, huffman_tree):\n",
    "    decoded_string = ''  # Initialisation de la chaîne décodée\n",
    "    current_node = huffman_tree  # Initialisation du nœud courant\n",
    "    \n",
    "    # Parcourir chaque bit de la chaîne compressée\n",
    "    for bit in compressed_string:\n",
    "        if bit == '0':\n",
    "            current_node = current_node[0]  # Si le bit est 0, se déplacer vers le nœud de gauche\n",
    "        else:\n",
    "            current_node = current_node[1]  # Sinon, se déplacer vers le nœud de droite\n",
    "        \n",
    "        # Si le nœud actuel est une feuille (représentée par une chaîne), ajouter le caractère correspondant à la chaîne décodée\n",
    "        if isinstance(current_node, str):\n",
    "            decoded_string += current_node\n",
    "            current_node = huffman_tree  # Réinitialiser le nœud courant pour recommencer\n",
    "        \n",
    "    return decoded_string  # Retourner la chaîne décodée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (9). $Codage$ $par$ $LZW$\n",
    "\n",
    "## (-). $Fonctions$ $intermediaires$\n",
    "\n",
    "### $Fusion$ $de$ $la$ $liste$ $des$ $codes$ $Huffman$ $de$ $tous$ $les$ $blocs$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionner(strings_list):\n",
    "    tailles = []  # Initialisation de la liste des tailles des chaînes\n",
    "    string_fusionned = \"\"  # Initialisation de la chaîne fusionnée\n",
    "    \n",
    "    # Parcourir tous les éléments de la liste\n",
    "    for string in strings_list:\n",
    "        # Ajouter chaque élément à la chaîne fusionnée\n",
    "        string_fusionned += string\n",
    "        \n",
    "        # Ajouter la taille de l'élément à la liste des tailles\n",
    "        tailles.append(len(string))\n",
    "    \n",
    "    # Retourner la chaîne de caractères fusionnée et la liste des tailles\n",
    "    return string_fusionned, tailles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Separation$ $of$ $the$ $list$ $of$ $Huffman$ $codes$ $from$ $all$ $the$ $blocks$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separer(string_fusionned, tailles):\n",
    "    strings_list = []  # Initialisation de la liste des chaînes séparées\n",
    "    debut = 0  # Initialisation de la position de début\n",
    "    \n",
    "    # Parcourir toutes les tailles dans la liste\n",
    "    for taille in tailles:\n",
    "        # Extraire le sous-chaîne correspondant à la taille actuelle\n",
    "        sous_chaine = string_fusionned[debut:debut+taille]\n",
    "        \n",
    "        # Ajouter la sous-chaîne à la liste des chaînes séparées\n",
    "        strings_list.append(sous_chaine)\n",
    "        \n",
    "        # Mettre à jour la position de début pour la prochaine sous-chaîne\n",
    "        debut += taille\n",
    "    \n",
    "    # Retourner la liste des chaînes séparées\n",
    "    return strings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Coding$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lzw_encoding(data):\n",
    "    alphabet = ['0', '1']  # Définition de l'alphabet initial\n",
    "    data_fused, taille = fusionner(data)  # Fusionner les chaînes de caractères\n",
    "    encoded_data = []  # Initialisation de la liste des données encodées\n",
    "\n",
    "    dictionary = {}  # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[char] = i\n",
    "\n",
    "    prefix = ''  # Initialisation du préfixe\n",
    "    for char in data_fused:\n",
    "        new_entry = prefix + char  # Concaténation du préfixe et du caractère actuel\n",
    "        if new_entry in dictionary:  # Si la nouvelle entrée est dans le dictionnaire\n",
    "            prefix = new_entry  # Mettre à jour le préfixe\n",
    "        else:\n",
    "            encoded_data.append(dictionary[prefix])  # Ajouter l'indice du préfixe à la liste des données encodées\n",
    "            dictionary[new_entry] = len(dictionary)  # Ajouter la nouvelle entrée au dictionnaire avec un nouvel indice\n",
    "            prefix = char  # Réinitialiser le préfixe au caractère actuel\n",
    "\n",
    "    if prefix:\n",
    "        encoded_data.append(dictionary[prefix])  # Ajouter l'indice du préfixe final à la liste des données encodées\n",
    "\n",
    "    return encoded_data, taille  # Retourner les données encodées et la taille des données originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Decoding$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lzw_decoding(compressed_data, taille):\n",
    "    alphabet = ['0', '1']  # Définition de l'alphabet initial\n",
    "    result = []  # Initialisation de la liste des données décodées\n",
    "    dictionary = {}  # Initialisation du dictionnaire de décodage\n",
    "    current_code = len(alphabet)  # Initialisation du prochain code disponible dans le dictionnaire\n",
    "\n",
    "    # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[i] = char\n",
    "\n",
    "    # Récupérer le premier code et le traduire en caractère\n",
    "    old_entry = dictionary[compressed_data[0]]\n",
    "    result.append(old_entry)\n",
    "\n",
    "    # Parcourir les codes compressés\n",
    "    for new_entry in compressed_data[1:]:\n",
    "        if new_entry in dictionary:  # Si le code est déjà dans le dictionnaire\n",
    "            entry = dictionary[new_entry]  # Récupérer la chaîne associée au code\n",
    "        elif new_entry == current_code:  # Si le code est égal au code actuel\n",
    "            entry = old_entry + old_entry[0]  # Construire une nouvelle entrée en ajoutant le premier caractère de l'ancienne entrée à l'ancienne entrée\n",
    "        else:\n",
    "            raise ValueError(\"Mauvaise séquence compressée\")  # Si le code n'est ni dans le dictionnaire ni égal au code actuel, lever une erreur\n",
    "\n",
    "        result.append(entry)  # Ajouter la nouvelle entrée à la liste des résultats\n",
    "\n",
    "        # Utiliser le même dictionnaire pour la décompression\n",
    "        dictionary[current_code] = old_entry + entry[0]  # Ajouter une nouvelle entrée au dictionnaire\n",
    "        current_code += 1  # Mettre à jour le code actuel\n",
    "        old_entry = entry  # Mettre à jour l'ancienne entrée pour la prochaine itération\n",
    "\n",
    "    result = ''.join(result)  # Convertir la liste des résultats en une seule chaîne de caractères\n",
    "    result = separer(result, taille)  # Séparer la chaîne fusionnée en chaînes de longueurs spécifiées\n",
    "\n",
    "    return result  # Retourner les données décodées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Intermediate$ $function$ for$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaire_compression(image):\n",
    "    # Convertir l'image RGB en YCrCb\n",
    "    ycrcb_image = rgb_to_ycbcr(image)\n",
    "    \n",
    "    # Effectuer le clustering K-Means pour obtenir une palette de couleurs\n",
    "    color_palette, palette_indices = kmeans_clustering_palette(ycrcb_image, 64)\n",
    "    \n",
    "    # Mapper chaque pixel de l'image à la palette de couleurs obtenue\n",
    "    mapped_indices = map_to_palette(ycrcb_image, color_palette)\n",
    "    \n",
    "    # Diviser l'image en blocs et sauvegarder les dimensions originales\n",
    "    blocks, original_dimensions = subdivision(mapped_indices, 8)\n",
    "    \n",
    "    # Initialiser des listes pour stocker les données compressées et les arbres de Huffman\n",
    "    compressed_texts = []\n",
    "    huffman_trees = []\n",
    "    \n",
    "    # Parcourir chaque bloc de l'image\n",
    "    for block in blocks:\n",
    "        # Réduire l'échantillonnage du bloc\n",
    "        downsampled_block = subsampling_4_4_4(block)\n",
    "        \n",
    "        # Effectuer un balayage linéaire sur le bloc et obtenir un vecteur compressé\n",
    "        compressed_vector, block_shape = linear_scan(downsampled_block)\n",
    "        \n",
    "        # Encoder le vecteur compressé avec RLE\n",
    "        encoded_string = rle_encode(compressed_vector)\n",
    "        \n",
    "        # Encoder la chaîne RLE avec Huffman\n",
    "        compressed_text, huffman_tree = huffman_encoding(encoded_string)\n",
    "        \n",
    "        # Ajouter les données compressées et l'arbre de Huffman aux listes respectives\n",
    "        compressed_texts.append(compressed_text)\n",
    "        huffman_trees.append(huffman_tree)\n",
    "    \n",
    "    # Encoder les données compressées avec LZW\n",
    "    encoded_data, compressed_size = lzw_encoding(compressed_texts)\n",
    "    \n",
    "    # Retourner les données compressées, les dimensions originales, la palette de couleurs,\n",
    "    # les indices de la palette, la forme du bloc, les arbres de Huffman et la taille de l'encodage\n",
    "    return encoded_data, original_dimensions, color_palette, palette_indices, block_shape, huffman_trees, compressed_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Intermediate$ $function$ $for$ $decompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaire_decompression(encoded_data, original_dimensions, color_palette, palette_indices, block_shape, huffman_trees, compressed_size):\n",
    "    # Décompresser les données LZW avec la taille fournie\n",
    "    decompressed_texts = lzw_decoding(encoded_data, compressed_size)\n",
    "    \n",
    "    # Initialiser une liste pour stocker les blocs décompressés\n",
    "    decompressed_blocks = []\n",
    "    \n",
    "    # Parcourir chaque bloc décompressé\n",
    "    for i, text in enumerate(decompressed_texts):\n",
    "        # Décompresser les données Huffman en utilisant l'arbre de Huffman correspondant\n",
    "        decoded_text = huffman_decoding(text, huffman_trees[i])\n",
    "        # Décoder la chaîne RLE\n",
    "        decompressed_vector = rle_decode(decoded_text)\n",
    "        \n",
    "        # Reconstruire le bloc à partir du balayage linéaire\n",
    "        block = inverse_linear_scan(decompressed_vector, block_shape)\n",
    "        \n",
    "        # Inverser le sous-échantillonnage du bloc\n",
    "        block = inverse_subsampling_4_4_4(block)\n",
    "        \n",
    "        # Ajouter le bloc décompressé à la liste\n",
    "        decompressed_blocks.append(block)\n",
    "    \n",
    "    # Reconstituer l'image à partir des blocs décompressés et des dimensions originales\n",
    "    reconstructed_indices = reconstitution(decompressed_blocks, original_dimensions)\n",
    "    \n",
    "    # Appliquer la transformation inverse pour mapper les indices à la palette de couleurs\n",
    "    decompressed_image = inverse_map_to_palette(reconstructed_indices, color_palette)\n",
    "    \n",
    "    # Reconstruire l'image RGB à partir de l'image YCrCb\n",
    "    reconstructed_palette = inverse_kmeans_clustering_palette(color_palette, palette_indices)\n",
    "    rgb_image = ycbcr_to_rgb(decompressed_image)\n",
    "    \n",
    "    # Retourner l'image RGB décompressée\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Creation$ $of$ $the$ $part$ $\"header\"$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_irm(path):\n",
    "    # Ouvrir l'image à partir du chemin spécifié\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    # Appeler la fonction intermediaire_compression pour obtenir les informations nécessaires\n",
    "    # et retourner toutes les informations sauf la première (les dimensions originales)\n",
    "    return intermediaire_compression(image)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Function$ $to$ $write$ $into$ $a$ $file$ $text$ $the$ $compressed$ $data$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecrire_data(fichier, liste):\n",
    "    # Ouvrir le fichier en mode écriture\n",
    "    with open(fichier, \"w\") as f:\n",
    "        # Convertir chaque entier en chaîne de caractères et les joindre avec un seul espace\n",
    "        ligne = \" \".join(map(str, liste))\n",
    "        # Écrire la ligne dans le fichier\n",
    "        f.write(ligne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Function$ $to$ $read$ $the$ $compressed$ $text$ $file$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_data(fichier):\n",
    "    # Ouvrir le fichier en mode lecture\n",
    "    with open(fichier, \"r\") as f:\n",
    "        # Lire la ligne du fichier et diviser les valeurs en une liste d'entiers\n",
    "        ligne = f.readline()\n",
    "        liste_entiers = list(map(int, ligne.split()))\n",
    "    return liste_entiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Function$ $for$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_irm(path11, path12):\n",
    "    # Ouvrir l'image à compresser à partir du chemin spécifié\n",
    "    img_img = Image.open(path11)\n",
    "    \n",
    "    # Appeler la fonction intermediaire_compression pour compresser l'image\n",
    "    image_file = intermediaire_compression(img_img)\n",
    "    \n",
    "    # Écrire les données compressées dans un fichier\n",
    "    ecrire_data(path12, image_file[0])\n",
    "    \n",
    "    # Afficher un message indiquant que l'image compressée a été sauvegardée avec succès\n",
    "    print(\"Image compressée sauvegardée avec succès dans le fichier : {}\".format(path12))\n",
    "    \n",
    "    # Retourner toutes les informations sauf les données compressées\n",
    "    return image_file[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Function$ $for$ $decompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompression_irm(header, path21, path22):\n",
    "    # Décompresser les données en utilisant les informations fournies dans l'en-tête\n",
    "    img_img = intermediaire_decompression(lire_data(path21), header[0], header[1], header[2], header[3], header[4], header[5])\n",
    "    \n",
    "    # Sauvegarder l'image décompressée dans le chemin spécifié\n",
    "    img_img.save(path22)\n",
    "    \n",
    "    # Afficher un message indiquant que l'image décompressée a été sauvegardée avec succès\n",
    "    print(\"Image décompressée sauvegardée avec succès dans le fichier : {}\".format(path22))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
